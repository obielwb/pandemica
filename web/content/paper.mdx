## Abstract

Since the outbreak of COVID-19 in late 2019, the world has witnessed unprecedented global impacts, resulting in millions of deaths and ongoing economic, political, and social crises. As new potentially pandemic diseases like monkeypox continue to emerge, the development of effective methods to predict and mitigate the impacts of epidemic outbreaks is increasingly crucial. This study introduces an innovative agent-based simulation model that leverages a neural network-like artificial intelligence algorithm to assign demographic and economic data to each agent, allowing for the simulation of individualized behavioral routines. This new approach enhances the accuracy of current epidemiological predictions by adapting to real-world data and scenarios on a local city scale.

The model is designed to be open-source, highly accessible, and focused on local scopes within municipal health departments, requiring basic epidemiological knowledge for operation on standard computers. Users can input demographic data from censitary agencies, such as the Brazilian Institute of Geography and Statistics (IBGE), and specific disease characteristics, which the model uses to simulate disease spread tailored to individual cities. This flexibility allows public health officials to adjust parameters such as mask-wearing and vaccination rates to see their effects on disease dynamics, providing actionable, city-scale insights that can be quickly leveraged to minimize loss of life and optimize resource allocation.

By integrating mathematical, biological, and technological concepts, the proposed model serves as a generic tool for simulating the outspread of respiratory infectious diseases, offering reliable epidemiological reports across various hypothetical scenarios. Already being implemented by health secretariats in Campinas and Bragança Paulista, the model stands as an innovative, go-to tool for public health crisis management, aiming to identify the most efficient ways to navigate public health crises with minimal impact on human life and economic stability.

## Introduction

The world has been suffering from the consequences of the COVID-19 pandemic since the end of 2019, when the virus began to spread from the city of Wuhan, Hubei province, in the People's Republic of China. The World Health Organization (WHO) estimates that the total number of deaths directly and indirectly associated with the COVID-19 pandemic (described as "excess mortality") between January 1, 2020, and December 31, 2021, was approximately 14.9 million (ranging between 13.3 million and 16.6 million).

Globally, various prevention and containment measures were implemented, such as social distancing, quarantine, lockdown, and subsequent vaccination (ARBEL; PLISKIN, 2022), significantly mitigating the spread of the virus. With the emergence of new potential pandemic pathologies (JONES et al., 2008), such as the recent monkeypox (SOHAL et al., 2023), for example, there is an opportunity to use technology to implement accurate simulation models (COSTA; PEIXOTO, 2020) to discover preventive and remedial measures to mitigate the human, economic, and social impact caused by pandemics (FU et al., 2021).

Countries like South Korea, for example, integrated digital technology into government-coordinated containment and mitigation processes—including surveillance, testing, tracking of contaminations, and strict quarantine—that may be associated with the early flattening of the COVID-19 case incidence curve in the country (FERRETTI et al., 2020). It is increasingly evident the important role of implementing public health-related technologies and the remarkable discovery of strategies and responses to pandemics in innovative ways (WHITELAW et al., 2020).

This project aims to propose a simulation model based on the theory of cellular agents combined with probabilistic mathematics as a means to simulate populations whose individuals interact virtually, taking into account the aspect of disease spread. To create and validate this model, it is proposed to use the data obtained during the COVID-19 pandemic and the viral characteristics of the disease.

In the proposed model, we argue that it is not only possible to simulate the pandemic scenario, predicting the number of cases and deaths but also to study different containment and mitigation parameters, such as different uses of masks, social distancing, and vaccination, for example. In this way, it is possible to determine how each variable influences the overall pandemic scenario, allowing competent entities to know how each measure contributes to the fight against emerging diseases, and for the population to more clearly understand how their actions affect the pandemic as a whole, in order to better weigh them.

## Research Problem

How to propose a reliable pandemic simulation, incorporating characteristics of the virus and its spread among a population, capable of generating different hypothetical scenarios based on changes in virus mitigation and combat variables, leveraging the most of city-scale data?

## Hypothesis

The use of cellular agents has great potential for simulating large populations of virtually living individuals (WHITE, 2007), who possess some form of intelligence, making the modeling of a virtual epidemic technically feasible. By adopting relevant and pertinent mathematical relations (WILLOX, 2003), biological characteristics, and epidemiological bulletins, in conjunction with suitable technologies, it is expected to establish an effective, accurate simulation model capable of generating pandemic reports that are faithful to the numbers of cases and deaths in various simulated scenarios, compared to the real outspread of the disease within a city-level scope.

## Justification

The COVID-19 pandemic has caused significant impact on public health and the global economy since its onset in 2019 (FU, 2021). By the beginning of 2023, the pandemic had caused an estimated global loss of USD 29.4 trillion (VISCUSI, 2023), in addition to impacts on the physical and mental health of the population, and an increase in waste generation (organic and inorganic), which have direct and indirect impacts on the environment, such as air, water, and soil pollution (ISLAM et al., 2016). Events like these result in significantly negative impacts on society and its environment. In this sense, it is extremely necessary that measures be taken to prevent and contain the next major pandemic.

However, although there is extensive literature on the mathematical modeling of COVID-19, studies and models that investigate the simulation of the spread of epidemiological outbreaks at a local level are scarce, considering various factors such as the population and physical characteristics of a given city, combined with general disease data, such as viral and behavioral characteristics. In this way, the impact of potential pandemics can be contained and mitigated on state, national, and international scales by addressing the spread and development of a pathology at the municipal level. In this regard, this study proposes the use of concepts from theoretical computing and mathematics, as well as algorithms and data structures, composing a simple yet robust pandemic simulation paradigm.

This research is relevant as it can provide important information for public managers' decision-making regarding the fight against emerging diseases. Additionally, it can contribute to the global development of more effective pandemic control strategies, considering viral particularities, but mainly regional specifics.

Finally, conducting this research is also pertinent as it expands knowledge on the application of cellular agents in epidemiology and strengthens collaboration between the institution and other organizations working on pandemic themes.

## Scope

Human behavior modeling is an extremely complex system due to the diversity and variability inherent in actions and decisions. Humans respond to stimuli influenced by a range of factors, including past experiences, social context, emotions, and health states. Human behavior is adaptive, meaning people can learn and change their behavior over time, making modeling this system in its entirety computationally and mathematically challenging.

Thus, we decided to abstract and simplify various factors in this simulation, such as individual behavior, which, instead of being random, will be a constant defined by a fixed number of limited activities. The city's simulation, also a complex system, required abstraction; therefore, we do not deal with a 100% accurate scenario or all the different activities and places that may exist. However, a wide range of activities has been created to generally encompass all the main actions performed in an urban environment in the 21st century.

We chose to use COVID-19 data for project development and validation as it is the most recent example of a pandemic pathology, with a large availability of data facilitating tests and model validation. Campinas was chosen for the city due to its location as our educational institution and its significance as a major industrial and population center in São Paulo. It's important to note that with census records, virtually any city in the world can be used in the simulation, as data entry is generic.

## Objectives

**General objective**

Create an effective pandemic simulation model that can minimize the impact of potential future pandemics by creating different scenarios that act as awareness tools for competent entities and for the population to act preventively in the midst of a potential pandemic.

**Specific objectives**

The specific objectives of this research are:

- To incorporate the technical and theoretical foundation of epidemiology;
- Analyze the theoretical base and literature on the viral characteristics of COVID-19;
- Collect geographic and demographic data from Campinas, transposing it virtually;
- Study and develop algorithms based on the behavior of agents suitable for simulating individuals in a virtualized pandemic environment;
- Elaborate the practical implementation of the theoretical foundations of dissemination in a computational model using systemic methodologies and techniques, incorporating epidemiological data;
- Test and evaluate the effectiveness of the system, based on real data collected from epidemiological bulletins, databases, and reports provided by the government;
- Establish a generic pandemic simulation model, capable of simulating the unfolding of a pandemic in any city with Census data and mainly respiratory pathology.

## Background

Aiming to promote a better approach to pandemic simulation and, consequently, greater accuracy for the simulation, the system to be developed utilizes the union of various algorithms, concepts of theoretical computer science, and mathematical modeling of disease dissemination to achieve this goal. Therefore, it becomes crucial to understand, primarily, the studies of virus spread analysis, the characteristics of the virus that will be simulated (COVID-19), the field of cellular automata theory in conjunction with existing epidemiological approaches, and their mathematical basis.

<details>
<summary>**Multi-agent systems**</summary>

Multi-agent systems are systems composed of intelligent agents that are situated in an environment and are capable of interacting to solve complex problems (WOOLDRIDGE, 2009). An agent can be seen as a computer system capable of responding to input stimuli (called perceptions), and through a process of reasoning and planning, generate an output in the form of actions in the environment (WOOLDRIDGE, 2009). The multi-agent system paradigm provides the benefits of: (i) enabling the resolution of complex problems in a distributed manner, without a central processing and failure point, where resources and capabilities are distributed across a network of interconnected agents; (ii) allowing the modeling of systems through the design of autonomous intelligent agents, capable of communicating, as the main component; and (iii) within the context of this work, enabling the simulation of behaviors of complex entities, such as human beings.

</details>

<details>
<summary>**Mathematical modeling in disease dissemination**</summary>

Although it was in Hippocrates' "Epidemics" that the quest for understanding the dynamics of epidemic spread began, Bernoulli is considered a pioneer in the field of mathematical modeling in epidemiology. In his 1760 work, he demonstrated the effectiveness of the variolation technique, which involved the inoculation of benign smallpox to prevent complications from the disease (BERNOULLI, 1760). However, it was in 1927 that Kermack and McKendrick proposed what can be seen as the starting point for the design of current mathematical models (KERMACK; MCKENDRICK, 1927); the SIR model. Different types of mathematical models can be taken into account, depending on the division of the population to be modeled. The mentioned SIR model segments individuals as (ALMEIDA, 2014):

- Susceptible: Individuals who have not yet developed immunity against the infection, meaning they can become infected if exposed to it.
- Infected: Individuals who have contracted the disease and have the capacity to transmit it to susceptible people.
- Recovered: Individuals who have recovered from the infection and acquired immunity, therefore, do not contribute to the spread of the disease.

Many infections have a time interval in which an individual has been infected but does not yet show symptoms or presents an asymptomatic condition; during this time, the epidemiological process is called incubation (ALENE, 2021), the individual is considered exposed. In this case, the SEIR model presents a new class of individuals, characterized by the letter "E" for exposed, in the acronym. Some infections, such as those caused by the coronaviruses responsible for the common cold, do not confer lasting immunity, lacking a defined recovery phase (EDRIDGE, 2020). Therefore, after an infection, individuals become susceptible again. In this case, the SIS models are configured. From the exposed models, there are other derivations, such as SIRS or SEIRS. According to the characteristics of COVID-19, the SEIR model is found to be the most appropriate to be incorporated into the simulation.

Figure 1 - Visual representation of the SEIR model

![](/paper/figure-2.png)

Source: Own Authorship (2023)

In addition, the SEIR model can be implemented analytically through differential equations presented in equations (1), (2), (3), and (4). In all the presented equations, 𝑡 refers to time in days.

E: Exposed (latent) humans

ε: Per capita rate of progression to infectious state

/ = Λ − β − µ γ − µ . (1) / = β − ε (2)

/ = ε − γ − µ (3)

/ = γ − µ (4)

Figure 3 - Epidemiological dynamics of the SEIR model

![](/paper/figure-3.png)

Source: Own Authorship (2023)

</details>

<details>
<summary>**Relevant epidemiological concepts**</summary>

Viruses are "on the brink of life and death" (ANDREWES, 1967). Under a microscope, a virus appears as a dead geometric crystal. However, when it makes a living cell its host, it can replicate rapidly.

A virus is essentially made up of two parts: genetic material and a protein capsule. In simplified terms, after infiltrating a cell, the virus rewrites the cell's DNA and transforms it so that it produces hundreds or even thousands of copies of itself. When these virus copies leave the affected cell, they become lifeless again until they enter another cell and the cycle is restarted. The cellular damage caused by the genetic rewriting process causes the disease. Figure 4 represents the infectious process of viral diseases.

Figure 4 - The relationship between virus infectivity and symptoms

![](/paper/figure-4.png)

Source: Rhodes (1996)

The labels above the line in Figure 4 describe the host's infectivity, while those below the line describe the disease dynamics. Note that the infectious period may begin before or after the onset of symptoms.

- Latent Period: This is the time interval during an infection in which the virus has not yet developed the potential to transmit to a new host.

- Infectious Period: During this phase, the virus is contagious and can be transmitted to others using organic propagation mechanisms.

- Recovered or Removed: In terms of viruses, a host who has developed natural immunity or died is no longer capable of contributing to the reproduction process. The virus, therefore, cannot reproduce in either scenario.

- Incubation Period: At the beginning of an infection, there may be no signs of infection; this is known as the incubation period. Viruses reproduce most during the junction of this phase and the infectious period (RHODES, 1996). This is due to the fact that hosts are unaware they are infected, maintaining normal interaction with other potential hosts, who are still healthy.

- Symptoms: This is the stage of infection when there are apparent indicators of infection. Treatment for viral infections usually consists of relieving symptoms and separating uninfected people.

</details>

<details>
<summary>**Flattening the curve**</summary>

In the context of infectious disease outbreaks, such as pandemics, "flattening the curve" has emerged as a critical technique for controlling and managing the spread of diseases. The goal of flattening the curve is to slow the rate of infection, minimize pressure on healthcare systems, and ultimately save lives.

The phrase "flattening the curve" refers to an epidemiological curve, often graphically represented, which shows the number of new cases of an infectious disease over time. In an uncontrolled outbreak, the curve exhibits a rapid and sharp rise, indicating a significant increase in the number of infections in a short period of time. This sharp curve implies a significant burden on healthcare systems, potentially overwhelming hospitals and leading to an increase in severe cases and deaths.

Figure 5 - Graph of flattening the curve

![](/paper/figure-5.png)

Source: Daud (2022)

"Flattening the curve" aims to address the challenges posed by a sharp epidemiological curve. The main goals of this strategy include:

- Slowing the spread: The curve can be flattened by applying measures to reduce the rate of transmission, such as social distancing, wearing masks, and hygiene practices. Slowing the disease spread allows healthcare systems to better manage the flow of cases, ensuring that those who need medical attention receive adequate care.- Evitar a sobrecarga do sistema de saúde: Ao diminuir o número de novos casos por dia, a demanda por recursos de saúde, como leitos hospitalares, ventiladores e equipe médica, pode ser adiada por um período de tempo mais longo. Isso evita que os sistemas de saúde fiquem sobrecarregados, permitindo que eles ofereçam um melhor atendimento ao paciente e melhorem os resultados gerais.
- Preventing healthcare system overload: By decreasing the number of new cases per day, the demand for healthcare resources, such as hospital beds, ventilators, and medical staff, can be spread over a longer period. This prevents healthcare systems from being overwhelmed, allowing them to provide better patient care and improve overall outcomes.

</details>

<details>
<summary>**Prevalence and incidence**</summary>

In epidemiology, prevalence is defined as the proportion of the population with a condition at a specific moment (point prevalence) or over a period (period prevalence) (KIER, 2011). Prevalence increases when new cases of disease are identified (incidence) and decreases when a patient is cured or dies. Often, period prevalence will provide a more accurate picture of overall prevalence because it includes all individuals with the disease between two dates: old and new (incident) cases, as well as those who were cured or died during the period (WHITING, 2015).

</details>

<details>
<summary>**Analysis of virus behavior in different environments**</summary>

Various factors influence the spread of the virus in a particular environment, such as social, economic, hygienic, and atmospheric factors, in addition to the characteristics of the virus itself. To address the behavior of COVID-19, we first need to understand its transmission model.

COVID is primarily transmitted by small droplets produced when an infected person talks, coughs, or sneezes, many of which can remain suspended in the air for minutes to hours. Touching contaminated surfaces or objects is possibly a way of spreading COVID, but the Centers for Disease Control and Prevention (CDC), an agency of the United States Department of Health and Human Services, believes that the main way of spread is from person to person through respiratory droplets. Therefore, in this research, we focus mainly on the risk of droplets expelled into the air.

</details>

<details>
<summary>**Reference interaction**</summary>

We start by estimating the risk of interacting with a single COVID-19 positive person indoors for 1 hour at a normal socialization distance of 1 meter during a normal volume conversation.

_Activity risk: Talking with 1 person with COVID-19, for 1 hour, indoors, without a mask, at 1 meter = 14%_

For this estimate, studies of passengers on trains (HU et al., 2021), aerosol transmission models (JIMENEZ, 2022), using contact tracing data, meta-analyses (CHU et al., 2020), and prospective studies (CHENG et al., 2020) were combined. From this estimate, the 14% can be multiplied by 1.5x based on the increased contagion of the B117 variant (DAVIES et al., 2013) and again by 1.5x as a consequence of the Delta variant (DAVIES et al., 2013).

This defines a "reference interaction," which will be used as a starting point to estimate the risk of other types of interactions.

</details>

<details>
<summary>**Modifiers**</summary>

There are various modifiers for the risk of activity, such as mask usage, being outdoors, ventilation, distancing, among others. These factors influence the probability of virus spread and must be analyzed.

To estimate the risk of activity from different interactions, we modify our estimate based on how the interaction in question differs from the reference interaction above, based on the following factors:

- Duration of the interaction
- Masks
- Location (outdoor or indoor)
- Distance between individuals
- Volume of conversation

The estimates for these modifiers are:

Table 1 - Modifiers in the risk of contracting COVID-19

| Modifier                                               | Change in the risk of contracting COVID-19 |
| ------------------------------------------------------ | ------------------------------------------ |
| I am wearing a surgical mask                           | / 2                                        |
| Another person is wearing a surgical mask              | / 4                                        |
| External environment                                   | / 20 or more                               |
| 2 meters distance                                      | / 2                                        |
| For each additional meter of distance (up to 4 meters) | / 2                                        |
| Speaking loudly (yelling, talking over music, singing) | x 5                                        |
| Not speaking (such as riding a train)                  | / 5                                        |

Source: Adapted from Lindsley et al. (2020), van der Sande et al. (2008), Davies et al. (2013), Jimenez (2022), Chu et al. (2020), Hu et al. (2021), Hua et al. (2020), Lai et al. (2012), O'Kelly et al. (2020), and Steinhauer (2020)

</details>

<details>
<summary>**Masks**</summary>

Most sources are drawn from _An Evidence Review of Face Masks against COVID-19_ (HOWARD et al., 2021), which examines a variety of study types, some specific to COVID-19 and others that study particle filtering as a property of the fabric or for other pathogens, such as influenza.

The estimate begins with a numerical reduction in contamination for each aspect of surgical masks. The table below shows the various results of these studies:

Table 2 - Characteristics of surgical masks and the respective reduction in pathogen contamination

| Measure                                       | Result                         |
| --------------------------------------------- | ------------------------------ |
| Proportion of cough aerosol blocked           | 60% (1.7x reduction)           |
| Protection factor                             | 2\.5x                          |
| Reduction of viral copies                     | 3\.4x                          |
| Reduction of "fine" aerosols                  | 2\.8x                          |
| Reduction of "coarse" aerosols                | 25x                            |
| Reduction of colony-forming units             | 7x                             |
| Proportion of airflow leakage around the mask | 12% (Maximum protection of 8x) |
| Reduction in cough droplet count              | 10x                            |

Source: Adapted from Lindsley et al. (2020), van der Sande et al. (2008), Milton et al. (2013), Davies et al. (2013), Kumar et al. (2005), and Fischer et al. (2020)

It is concluded that surgical masks are substantially better at blocking large particles (25x) than small particles (2.8x) (MILTON et al., 2013). Coughing seems to be filtered extremely efficiently (DAVIES et al., 2013) and (FISCHER et al., 2020), which implies that they are mainly large particles. As a result, a slightly higher number than the total value cited in _Influenza Virus Aerosols in Human Exhaled Breath: Particle Size, Culturability, and Effect of Surgical Masks_ (MILTON et al., 2013), (3.4x), is set at 1/4.

Estimates are obtained for thin and thick cotton masks which offer less protection to others, comparing them with surgical masks and among themselves. A "scarf" is approximately 56-65% as protective as a surgical mask, while a "cotton blend" is approximately 70-78% as protective (DAVIES et al., 2013)

A homemade mask is approximately 92% as effective as a surgical mask in blocking colony-forming units (DAVIES et al., 2013). Overall, a thick, well-fitting cotton mask is about 80% to 90% as effective as a surgical mask (which according to estimates reduces exposure by 4x), resulting in 2.5x-3x protection, which we round up to 3x (1/3 multiplier) for thick cotton masks. As a result, a thinner or poorly fitting homemade mask appears to be at least 50% as effective as a surgical mask, which we round to 2x (1/2 multiplier).

</details>

<details>
<summary>**Vaccination**</summary>

In an unvaccinated population, 17% of cases never show symptoms, and these individuals are 42% more likely to transmit COVID than those who eventually show symptoms (BYAMBASUREN et al., 2020).

From this, it is calculated that for every infection, there are 0.83 symptomatic infections and 0.17 asymptomatic infections, or for every symptomatic infection, there are approximately 0.2 asymptomatic infections. Only the vaccine brands administered in Brazil will be studied, including AstraZeneca, Pfizer, CoronaVac, and Johnson & Johnson, along with their infectivity rates and efficacy.

<details>
<summary>**AstraZeneca**</summary>

The AstraZeneca trial study conducted by the University of Oxford in 2021 reported that among fully vaccinated participants, there were 57 asymptomatic cases and 84 symptomatic cases, or 0.68 asymptomatic cases per symptomatic case.

There was a 59.8% reduction in symptomatic COVID cases among fully vaccinated individuals with the AstraZeneca vaccine (BERNAL et al., 2021).

For every symptomatic case among unvaccinated people, this gives us:

Table 3 - Analysis of AstraZeneca vaccine efficacy

|                    | Control Group | Vaccinated Group |
| :----------------- | ------------- | ---------------- |
| Symptomatic cases  | 1             | 0,4              |
| Asymptomatic cases | 0,2           | 0,4\*0,68 = 0,27 |

Source: Adapted from Byambasuren et al. (2020)

Treating asymptomatic cases as having 0.4 relative infectivity, this results in an adjusted infectivity rate of:

(0, 4 + 0, 4 \* 0, 27) / (1 + 0 , 4 \* 0, 2) = 0, 47

</details>

<details>
<summary>**Pfizer**</summary>

Pfizer showed a 95% reduction in symptomatic COVID cases (POLACK et al., 2020). The CDC showed that there was a 90% reduction in all cases (symptomatic + asymptomatic) 14 or more days after participants received the Pfizer vaccine (THOMPSON et al., 2021).

Then, the number of asymptomatic cases among vaccinated individuals is recalculated based on these studies:

1. For each symptomatic case among unvaccinated people, there are 0.2 asymptomatic cases, or 1.2 cases in total (BYAMBASUREN et al., 2020)
2. For each symptomatic case among unvaccinated people, there are 0.05 symptomatic cases among vaccinated.
3. For each total case among unvaccinated people, there are 0.1 total cases among vaccinated people (CDC).
4. For each symptomatic case among unvaccinated people, there are 1.2 \* 0.1 = 0.12 total cases.
5. For each symptomatic case among unvaccinated people, there are 0.12 - 0.05 = 0.07 asymptomatic cases among vaccinated people.
6. For each symptomatic case among vaccinated people, there are 0.07 / 0.05 = 1.4 symptomatic cases among vaccinated people.

Then, this is combined with the study by Bernal et al., which found that the Pfizer vaccine is 87.9% (95% confidence interval: 78.2 to 93.2) effective in reducing the chance of symptomatic infection by the Delta variant.

Table 4 - Analysis of Pfizer vaccine efficacy

|                    | Control Group | Vaccinated Group   |
| :----------------- | ------------- | ------------------ |
| Symptomatic cases  | 1             | 0,12               |
| Asymptomatic cases | 0,2           | 0,12 \* 1,4 = 0,17 |

Source: Adapted from Byambasuren et al. (2020) and Bernal et al. (2021)

Treating asymptomatic cases as having 0.4 relative infectivity, this results in an adjusted infectivity rate of:

(0, 12 + 0, 4 \* 0, 17) / (1 + 0, 4 \* 0, 2) = 0, 17

</details>

<details>
<summary>**CoronaVac**</summary>

Among vaccinated participants, 51 tested positive for SARS-CoV-2 during follow-up (41 before and 10 after the second dose); 29 were diagnosed through asymptomatic screening, giving us 0.56 asymptomatic cases per symptomatic case (TANG et al., 2021)

No symptomatic positive cases or known exposure occurred more than 7 days after the second dose. Unvaccinated participants had a higher cumulative incidence of positive test results compared to vaccinated participants and a higher incidence of positive test results through asymptomatic screening, for symptoms or for known exposure.

For each symptomatic case among unvaccinated people, this gives us:

Table 5 - Analysis of CoronaVac vaccine efficacy

|                    | Control Group | Vaccinated Group    |
| :----------------- | ------------- | ------------------- |
| Symptomatic cases  | 1             | 0,4                 |
| Asymptomatic cases | 0,2           | 0,4 \* 0,56 = 0,224 |

Source: Adapted from Byambasuren et al. (2020)

Treating asymptomatic cases as having 0.4 relative infectivity, this results in an adjusted infectivity rate of:

(0, 4 + 0, 4 \* 0, 224) / (1 + 0, 4 \* 0, 2) = 0, 45

</details>

<details>
<summary>**Johnson & Johnson**</summary>

Johnson & Johnson conducted serological tests for antibodies unrelated to the spike protein on days 1, 29, and 71 to track asymptomatic infections. They also considered an asymptomatic infection if a participant had a positive PCR test but no symptoms. Symptomatic cases were accounted for when a patient had symptoms and tested positive on the PCR at least 14 days after the administration of the vaccine.

Table 6 - Analysis of Janssen vaccine efficacy

|                    | Control Group | Vaccinated Group     |
| :----------------- | ------------- | -------------------- |
| Symptomatic cases  | 1             | 0,36 (J&J Fase 3)    |
| Asymptomatic cases | 0,2           | 0,36 \* 0,18 = 0,065 |

Source: Adapted from Byambasuren et al. (2020)

Treating asymptomatic cases as having 0.4 relative infectivity, this results in an adjusted infectivity rate of:

(0, 36 + 0, 4 \* 0, 065) / (1 + 0, 4 \* 0, 2) = 0, 36

</details>
</details>

<details>
<summary>**Hospitalization and death rate by age group**</summary>

To more accurately represent the probability of COVID-19 contamination in the population, the susceptibility of each individual to contract the disease must be considered. Factors such as chronic health conditions/diseases (diabetes, heart diseases, lung diseases, etc.), age, and gender influence both the likelihood of contracting the disease and the rates of hospitalization and death (ASLANER, 2021).

Table 7 - Hospitalization and death rate by age group

|             | Hospitalization rate (%) | Death rate (%) |
| :---------- | ------------------------ | -------------- |
| 0-17 years  | 0\.8%                    | 0\.0015%       |
| 18-49 years | 2\.5%                    | 0\.07%         |
| 50-64 years | 7\.9%                    | 0\.7%          |
| 65+ years   | 5%                       | 6%             |

Source: Adapted from Aslaner et al. (2021)

</details>

## Methodology

**Critérios do Produto**

- Características da população, cidade e atividades que compõem as rotinas dos indivíduos podem ser alteradas, excluídas ou adicionadas;
- Cada indivíduo tem suas próprias características que os diferenciam dos demais, como idade, sexo, casa, escola e/ou trabalho, que são definidas a partir do senso da cidade a ser simulada;
- Algoritmo que distribua estas características únicas a todos os indivíduos na simulação;
- Algoritmo de disseminação do vírus que consiga, a partir do estado dos indivíduos, seu ambiente e características da doença determinar uma probabilidade de infecção;
- Todos os indivíduos possuem sua própria rotina com uma série de atividades pré definidas com base em suas características;
- É possível alterar variáveis de combate à doença, resultando assim em diferentes cenários pandêmicos.

**Materiais e softwares utilizados**

Para a análise exploratória dos dados e criação dos gráficos foram utilizadas bibliotecas da linguagem de programação Python em conjunto com Jupyter Notebook, devido ao seu fácil uso e uma gama de funcionalidades bastante acessíveis.

Para a simulação, foi utilizada a linguagem de programação TypeScript, que possui um ecossistema bastante popular, cuja comunidade e bibliotecas servem como facilitadoras do processo de desenvolvimento. Além disso, por ser derivada de JavaScript, a simulação pode ser convertida de forma a poder ser feita em qualquer website sem maiores complicações.

- Desenvolvimento:
  - Ambiente de desenvolvimento integrado (IDE);
  - Bibliotecas de processamento de matrizes e vetores Numpy e Pandas;
  - Bibliotecas de criação de gráficos e visualização de dados Matplotlib e Plotly;
  - Motor de execução Bun.
- Os computadores utilizados para realizar esta pesquisa possuem as seguintes especificações de _hardware_:
- Computador pessoal 1
  - Processador AMD Ryzen 5 5ª geração;
  - 24 GB de memória RAM;
  - Windows 11;
  - Armazenamento em disco de SSD M.2 NVMe 512 GB + HD 1TB.
- Computador pessoal 2
- Processador Intel i5 8ª geração;
- 8 GB de memória RAM;
  - Windows 11;
  - Armazenamento em disco de SSD SATA 480 GB.
- Computador pessoal 3
  - Processador Intel i7 10ª geração;
  - 8 GB de memória RAM;
  - Windows 11;
  - Armazenamento em disco de SSD PCLe 256 GB.
- Computador institucional
  - Processador Apple M1;
  - 16 GB de memória RAM;
  - macOS Ventura;
  - Armazenamento em disco de SSD M.2 NVMe 512 GB.

**Etapas**

**Representação da cidade virtualmente**

Representing a city virtually with accuracy and reliability is a challenge. Therefore, we chose to abstract the general dynamics of a city, based on the geographical concepts of fixity and flows. Fixities refer to the static elements of the city, such as buildings, roads, and other infrastructures, which are the permanent components that form the physical skeleton of the city. On the other hand, flows represent dynamic elements like the movement of people, vehicles, and information. These flows are crucial for determining the daily functioning of a city (BARROS, 2020).

In our modeling approach, we aim for a simplified representation that captures the essence of these two aspects. Although we focus on basic infrastructure and main movements within the city itself, we chose to simplify or omit certain more complex aspects, such as individual movements between neighboring cities. This simplification helps keep the model manageable and focused on the most critical aspects of urban dynamics.

In abstracting the city's representation, one approach is to create an a x b cell matrix, with each cell equivalent to 1m² of the actual city being used as the geographic location of an individual. We decided against this approach because it would waste memory in a state where a certain cell is not occupied by any individual. Instead, each individual has in their attributes the abstraction of location; they do not have defined coordinates but rather a state indicating their place. For example, in a city with 30,000 work points, when an individual is working, they do not have the exact coordinates of their job, but rather an identification, which is distinct from the other 30,000. Thus, when calculating virus spread in this environment, we look among the database of individuals for all those who, at that moment, have the same work point identification as the current individual.

To simulate the city, it is necessary to have the social and universal census of the place to obtain certain crucial information for the model. Due to the unavailability of recent data, the 2010 census from the Brazilian Institute of Geography and Statistics (IBGE) was used. We alert to the fact that, since the data refer to a city ten years in the past relative to the one that faced the COVID-19 pandemic, the results of deaths and cases may suffer minimal inconsistencies.

The requested information is important in defining the characteristics of individuals, their routines, and the rate of virus dissemination. Due to minor inconsistencies in the data obtained from the 2010 IBGE census, it was necessary to develop an algorithm to normalize the data.

**Representação dos indivíduos na cidade**

São atribuídas a cada indivíduo dentro da cidade certas atividades de forma aleatória com base em suas características definidas de acordo com os dados sociodemográficos. Estas atividades envolvem locomoção e encontro com outros indivíduos, que podem categorizar cenários de lazer, trabalho, ou estudo, e representam a rotina deste indivíduo na cidade.

Além das rotinas e suas próprias características, foi necessário distribuir a população em suas respectivas residências a fim de obter-se uma rotina de trabalho-casa ou escola-casa.

As residências foram distribuídas com base nos dados do IBGE, bem como a quantidade de indivíduos por residência. A idade destes indivíduos também foi levada em consideração nesta distribuição, uma vez que existem parâmetros relacionados. Por exemplo, é improvável um cenário no qual um indivíduo de zero a quatro anos mora em uma residência sozinho.

Portanto, a população virtual modelada apresenta características detalhadas análogas à vida real. Dessa forma, cada indivíduo possui os seguintes atributos devidamente distribuídos de acordo com os dados disponíveis, de forma coerente e pertinente:

- Identificação;
- Sexo;
- Faixa etária;
- Status educacional;
- Residência:
  - Identificação;
  - Região;
  - Número de residentes;
  - Residentes (demais indivíduos).
- Renda;
- Meio de transporte (público ou privado);
- Tipos de ocupação (trabalho e/ou estudo);
- Ocupações:
  - Identificação;
  - Tipo (trabalho e estudo);
  - Número de indivíduos.
- Vacina:
  - Tipo;
  - Doses.
- Máscara;
- Está hospitalizado?;
- Está morto?;
- Está com COVID?;
- Já teve COVID?;
- Rotina - conjunto de atividades compostas por:
- Identificação;
- Categoria (lazer, afazeres, trabalho, transporte, estudo, etc);
- Duração;
- Distância entre indivíduos;
- Volume da voz dos indivíduos;
- Ambiente (fechado ou aberto).

**Sincronização das atividades na simulação**

Para realizar a simulação de forma que as atividades sejam executadas no tempo certo, e que atividades futuras sejam apenas executadas quando as atuais terminarem, preservando a lógica do indivíduo não poder estar em diferentes lugares ao mesmo tempo, surge a necessidade da implementação de um algoritmo de sincronização destas atividades. Portanto, foram pesquisadas diferentes técnicas computacionais e teóricas para abordar o problema.

**NP-Hard e Algoritmo de Johnson**

Um problema é atribuído à classe NP (tempo polinomial não determinístico) se for solucionável em tempo polinomial por uma máquina de Turing não determinística (BORWEIN, 1987). Problemas NP-hard podem ser de qualquer tipo: problemas de decisão, problemas de pesquisa ou problemas de otimização.

O _Job-Shop Scheduling Problem_ (JSSP) é um problema de otimização combinatória, NP-hard. O objetivo do problema é encontrar a programação ideal para alocar recursos compartilhados ao longo do tempo para atividades concorrentes a fim de reduzir o tempo total necessário para concluir todas as atividades.

Em um JSSP, há um número de trabalhos ( 1, 2, ..., ), que precisarão ser concluídos usando um número de recursos compartilhados, mais comumente denotados como máquinas ( 1, 2, ..., ). Cada trabalho terá operações ( ) que precisarão ser concluídas em uma ordem específica para que o trabalho seja concluído. As operações devem ser concluídas em máquinas específicas e exigem um tempo de processamento ( ) nessa máquina (YAMADA, 1997).

O algoritmo heurístico de S. M. Johnson, ou simplesmente Algoritmo de Johnson é uma das soluções para o JSSP e se comporta da seguinte maneira:

O trabalho tem duas operações, de duração 1 e 2, a serem realizadas nas máquinas 1 e 2 nessa sequência.

1. Lista = \{ 1, 2, ..., }, Lista 1 = {}, Lista 2 = {}.
2. De todas as durações de operação disponíveis, escolha a mínima.

   Se o mínimo pertencer a 1,

   Remova da lista . Adicione ao final da lista 1. Se o mínimo pertencer a 2,

   Remova da lista . Adicione ao início da lista 2.

3. Repita a etapa 2 até que a Lista A esteja vazia.
4. Junte a Lista L1 e a Lista L2. Essa é a sequência ideal.

Nos inspiramos neste algoritmo para propor a lógica de abordagem da sincronização. Todas as atividades que estão acontecendo em determinado momento ficarão em um vetor (arranjo) ordenado de forma crescente de acordo com o tempo das atividades, ou seja, os primeiros índices do vetor conterão as atividades que estão acontecendo agora e que possuem o menor tempo dentre todas as outras.

Toda vez que uma nova atividade se inicia, é adicionada ao vetor e será acionado o algoritmo de disseminação para ela de acordo com suas características e de seus indivíduos, mudando seus estados de acordo com o resultado da disseminação.

O algoritmo de disseminação é acionado apenas uma vez para cada atividade. A cada momento, as atividades do início do vetor são computadas, seu tempo é adicionado ao tempo global da simulação e ela é removida do vetor, esse tempo é removido de todas as outras atividades acontecendo no momento. Após isso, é feita uma busca por todos os indivíduos para ver se a atividade em que estavam já acabou e se começam uma nova naquele tempo da simulação, e assim o vetor é ordenado novamente. Optamos por esta estratégia pois o tempo de execução do programa depende inteiramente da velocidade dos algoritmos de disseminação, ordenação e procura, e não há a necessidade de um gargalo proposital para alterar o tempo da simulação de acordo com um tempo real.

**Análise da eficácia de diferentes algoritmos de ordenação**

Para escolher qual algoritmo de ordenação será utilizado no vetor de atividades, realizamos diversos testes com diferentes algoritmos. A seguir está o gráfico mostrando a relação de tempo de execução, em segundos, por interação, mostrando a performance de cada algoritmo na ordenação de um milhão de atividades de duração aleatória, que simboliza o pior cenário possível onde cada indivíduo está em uma atividade diferente.

Figure 8 - Gráfico de análise dos algoritmos de ordenação

![](/paper/figure-8.jpeg)

Source: Own Authorship (2023)

A partir das análises dos dados, foi escolhido o algoritmo de _Quick Sort_ para ser utilizado no processo de ordenação das atividades, o que condiz com o fato de ser um dos mais eficientes e rápidos dentre todos os outros (XIANG, 2011), e ter complexidade temporal e espacial de ( ) nos melhores casos, proporcionando ótima performance.

**Utilização da fundamentação teórica para cálculo da probabilidade de disseminação da doença**

A disseminação é uma abstração do conceito de autômatos celulares na Vizinhança de Moore: o estado de saúde de cada indivíduo é alterado com base nos dados dos indivíduos virtualmente próximos a ele, dada uma regra fixa. Essa regra fixa é o fluxo de cálculo da probabilidade de disseminação da doença.

Esse fluxo é realizado, portanto, como uma linha de produção. De forma iterativa, o algoritmo extrai todas as informações começando a partir de cada característica e estado de saúde dos indivíduos, bem como características da atividade, ambiente virtual, parâmetros globais acerca do vírus, seu comportamento e probabilidades dos modificadores anteriormente definidos, como o tipo de máscara e vacina. Desse modo, é determinada a probabilidade de disseminação da doença utilizando as taxas de risco da atividade, risco individual de cada indivíduo e prevalência de casos na região. Todos os valores dos modificadores e exemplos de cálculos são mostrados durante a fundamentação teórica. Se esta probabilidade for maior que um limiar mínimo ainda a ser estipulado, é considerado que o indivíduo contraiu a doença.

Figure 9 - Fluxograma simplificado do funcionamento do projeto

![](/paper/figure-9.jpeg)

Source: Own Authorship (2023)

**Validação do modelo de disseminação utilizando o COVID-19**

Para simular diferentes cenários com diferentes configurações de uso de máscaras, distanciamento social e tráfego de pessoas, precisamos primeiro ter um modelo capaz de gerar o mesmo números de mortes e casos nas condições exatas do cenário real da pandemia. Desenvolvemos a seguinte metodologia para a validação do modelo:

Figure 10 - Metodologia para validação do modelo de disseminação

![](/paper/figure-10.png)

Source: Own Authorship (2023)

Antes de testarmos o modelo para a simulação de cenários dado características de doenças potencialmente epidêmicas recentes, precisamos primeiro validar utilizando dados de uma pandemia que já aconteceu, como a do COVID-19, pois senão não saberemos se os cenários simulados são verdadeiros ou não.

Para a validação, utilizamos o método de _Hold-out Validation_, que consiste em dividir os conjuntos de dados de boletins epidemiológicos dos anos 2020 a 2021 entre treinamento e teste, utilizando uma proporção de 80/20. Os 20% dos dados representam os primeiros meses da pandemia em 2020 e é utilizado para treinar o modelo, o qual com base nesses dados define variáveis de prevalência do vírus, taxa de aumento de casos, entre outros.

Após a incorporação dos dados iniciais o modelo se torna autossuficiente, mudando suas taxas e variáveis com base nos casos que ele mesmo gera. Ao final da simulação do período desejado, utilizamos os 80% dos dados restantes para validar a acurácia das predições.

## Resultados

No estágio atual de desenvolvimento da pesquisa, foi demonstrada na teoria e confirmada na prática a viabilidade computacional de modelagem de uma população virtual com atributos, características e rotinas análogas às de indivíduos em uma população real, com embasamento em dados geográficos e demográficos. No entanto, a implementação desse modelo provou ser desafiadora, exigindo a consideração de uma ampla gama de parâmetros para criar uma população virtual que seja minimamente relacionada à real.

Além disso, nossa pesquisa comprovou, até o presente momento, que é computacionalmente viável simular uma pandemia por meio de autômatos celulares que representam os indivíduos em uma cidade abstrata virtualizada. Essa abordagem tem o potencial de fornecer percepções valiosas sobre como as doenças infecciosas se disseminam e o quão eficaz cada tipo de intervenção é.

Como resultado parcial desta pesquisa, foram simulados, seguindo o embasamento bibliográfico, teórico e metodológico estabelecido, 3 anos da pandemia de COVID-19 em Campinas: de 2020 a 2023. Os gráficos abaixo representam, de forma ilustrativa, os resultados obtidos a partir da modelagem com a respectiva acurácia quando comparados com os dados reais.

Figure 11: Gráfico comparativo de casos totais ao longo do tempo

![](/paper/figure-11.jpeg)

Source: Own Authorship (2023)

Figure 12: Gráfico comparativo da distribuição de casos totais

![](/paper/figure-12.jpeg)

Figure 13: Gráfico comparativo de novos casos ao longo do tempo

![](/paper/figure-13.jpeg)

Source: Own Authorship (2023)

Figure 14: Gráfico comparativo de mortes ao longo do tempo

![](/paper/figure-14.jpeg)

Figure 15: Gráfico comparativo da distribuição de mortes

![](/paper/figure-15.jpeg)

Source: Own Authorship (2023)

Figure 16: Gráfico comparativo de novas mortes ao longo do tempo

![](/paper/figure-16.jpeg)

Source: Own Authorship (2023)
46

Figure 17: Gráfico comparativo de mortes por total de casos ao longo do tempo

![](/paper/figure-17.jpeg)

Source: Own Authorship (2023)

Figure 18: Gráfico comparativo de mortes por total de casos ao longo do tempo

![](/paper/figure-18.jpeg)

Source: Own Authorship (2023)

O cenário simulado reflete o uso de máscaras e a vacinação da população análogo ao que ocorreu de fato durante a pandemia. Os dados simulados, no entanto, mostram um número inflacionado de casos e mortes em comparação com os dados reais observados em Campinas durante o mesmo período. Especificamente, a simulação resultou em aproximadamente 720 mil casos e 20 mil mortes, enquanto em Campinas foram registrados cerca de 200 mil casos e 5 mil mortes.

Essa discrepância sugere a necessidade de mais testes e refinamento do modelo para aumentar sua acurácia. É importante melhorar o modelo não só em termos técnicos, mas também explorando e utilizando melhor os atributos de cada indivíduo. Após implementarmos tais modificações e melhorias, esperamos reduzir o número total de casos previstos pela simulação, evitando a hiper contaminação virtual que não ocorreu na realidade.

Embora o modelo atual precise de aprimoramentos, ele já demonstra potencial para prever o comportamento de novas doenças e cenários epidêmicos futuros. A ênfase deve ser colocada no aprimoramento e polimento do modelo para garantir que ele possa simular com mais precisão os impactos de intervenções de saúde pública, como vacinação e uso de máscaras, em diferentes cenários epidêmicos. Espera-se, como resultado final, que o modelo atinja uma acurácia de 50% a 60%, superando os atuais modelos, que atuam na faixa de 30% a 40%.

## Conclusões

A partir do objetivo inicial de criar um modelo capaz de simular doenças potencialmente pandêmicas em qualquer cenário virtual, foi proposta a utilização conjunta de diversas fontes de dados, embasamento matemático, conceitos computacionais teóricos e métodos a fim de se obter como produto um modelo de simulação acurado e confiável. Durante o trabalho, foi estudado a fundo cada aspecto da simulação, sua viabilidade, relação com conceitos interdisciplinares e a melhor maneira para ser implementado.

A idealização de tais métodos e sua validação teórica foi concluída, sendo possível estabelecer um modelo teoricamente capaz de simular uma pandemia em escala local, para, dessa forma, mitigar e reduzir os impactos de uma pandemia.

Atestamos para o fato de que embora o projeto esteja lidando com as características do vírus COVID-19 em Campinas, as bases teóricas e metodológicas podem e devem ser implementadas e adaptadas a outras doenças, principalmente respiratórias, e em qualquer cidade que disponha de algum tipo de censo geográfico e demográfico.

Também vale ressaltar que propomos e implementamos com sucesso um simulador pandêmico que se apropria de uma população com atributos detalhados a nível municipal, diferindo de implementações mais gerais, a nível nacional ou estadual, como em _Outbreak diversity in epidemic waves propagating through distinct geographical scales_ (COSTA; COTA; FERREIRA, 2020), e até mesmo adaptações municipais, como a implementação proposta em _Modeling the Spatiotemporal Epidemic Spreading of COVID-19 and the Impact of Mobility and Social Distancing Interventions_ (ARENAS et al., 2020), devido ao ineditismo de uma modelagem que direcionada exclusivamente à escala local. Dessa forma, a coleta e utilização de dados regionais em detrimento de abstrações macroscópicas resultaram em um modelo mais acurado e fidedigno, com baixos requisitos de poder computacional.

Portanto, a utilização de um _cluster,_ ou aglomerado, de diversos simuladores, cada um adequado para uma única cidade de acordo com os dados do censo, possibilita a simulação de escalas estaduais e nacionais constituídas, internamente, por estruturas mais específicas e direcionadas aos municípios, o que corrobora, por conseguinte, para simulações mais acuradas de forma geral.

Assim, obtivemos, como produto da pesquisa que ainda está em andamento, um simulador pandêmico que não se restringe apenas ao caráter matemático da clássica modelagem epidemiológica, como visto em _Spreading phenomena on complex networks and social systems_ (COTA, 2020), incluindo uma vasta gama de parâmetros biológicos, geográficos e demográficos de forma pioneira. Constitui-se, portanto, um modelo que é capaz de simular e predizer o comportamento futuro de potenciais pandemias, principalmente de doenças respiratórias, que pode ser licenciado ou vendido como um _Software as a Service_ (SaaS) para secretarias municipais ou estaduais de saúde, assim como ministérios e organizações competentes, como o Ministério da Saúde e a Organização Mundial de Saúde (OMS), possibilitando ações preventivas a fim de reduzir os impactos humanos, sociais e econômicos de um surto. Além disso, institutos e empresas públicas e/ou privadas do setor farmacêutico também podem se beneficiar de testes em cenários pandêmicos virtualizados da eficácia de suas vacinas, como Pfizer, Johnson & Johnson, AstraZeneca e o Butantã.

Por fim, esperamos que a mesma inspire trabalhos futuros a aprimorar os métodos que propusemos, bem como as técnicas existentes, com o objetivo de expandir ainda mais o domínio de novas bases teóricas no campo da simulação pandêmica computacional. Podendo contribuir para o desenvolvimento de estratégias mais eficazes de prevenção e resposta a pandemias no futuro, por exemplo, através do uso de aprendizado de máquina sobre os cenários simulados, elevando, ainda mais, as conclusões a serem tomadas sobre o decorrer de uma pandemia.
